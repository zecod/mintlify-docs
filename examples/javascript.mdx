---
title: "JavaScript/Node.js Examples"
description: Complete JavaScript and Node.js SDK examples for the NeoSpeech API
icon: "js"
---

## Installation

Install the official SDK:

```bash
npm install neospeech-io
```

## Basic Setup

```javascript
const NeoSpeech = require('neospeech-io');

const neospeech = new NeoSpeech(process.env.NEOSPEECH_API_KEY);
```

## Generate Speech

### Basic Example

```javascript
const fs = require('fs');

const audio = await neospeech.audio.speech({
  input: 'Hello, world!',
  voice: 'lyra',
  model: 'aurora-4'
});

// Save to file
fs.writeFileSync('output.mp3', Buffer.from(audio));
```

### Advanced Example with Options

```javascript
const audio = await neospeech.audio.speech({
  input: 'Welcome to our professional service!',
  voice: 'lyra',
  model: 'aurora-4',
  pitch: '+10%',
  style: 'cheerful',
  styleDegree: '1.8'
});

const buffer = Buffer.from(audio);
fs.writeFileSync('speech.mp3', buffer);
```

### Save Audio to File

```javascript
async function saveAudioToFile(text, filename, voice = 'lyra', model = 'aurora-3.5') {
  const audio = await neospeech.audio.speech({
    input: text,
    voice: voice,
    model: model
  });

  fs.writeFileSync(filename, Buffer.from(audio));
  console.log(`Audio saved to ${filename}`);
}

// Usage
await saveAudioToFile(
  'This is a test message.',
  'output.mp3',
  'lyra',
  'aurora-4'
);
```

## Stream Speech

### Basic Streaming

```javascript
const stream = await neospeech.audio.stream({
  input: 'Streaming test message',
  voice: 'kai',
  model: 'turbo-3'
});

const reader = stream.getReader();
const chunks = [];

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  chunks.push(value);
  console.log(`Received chunk: ${value.length} bytes`);
}

const audioBlob = Buffer.concat(chunks);
fs.writeFileSync('stream.mp3', audioBlob);
```

### Stream with Progress Callback

```javascript
async function streamSpeechWithProgress(text, voice, model, onProgress) {
  const stream = await neospeech.audio.stream({
    input: text,
    voice: voice,
    model: model
  });

  const reader = stream.getReader();
  const chunks = [];
  let receivedBytes = 0;

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    chunks.push(value);
    receivedBytes += value.length;

    if (onProgress) {
      onProgress({
        receivedBytes,
        chunks: chunks.length,
        latestChunkSize: value.length
      });
    }
  }

  return Buffer.concat(chunks);
}

// Usage
const audio = await streamSpeechWithProgress(
  'Long text content here...',
  'lyra',
  'aurora-3.5',
  (progress) => {
    console.log(`Progress: ${progress.receivedBytes} bytes, ${progress.chunks} chunks`);
  }
);
```

## Check Balance

```javascript
const balance = await neospeech.balance.get();

console.log(`Remaining credits: ${balance.balance.remaining_credits.toLocaleString()}`);
console.log(`Plan: ${balance.plan.type}`);
console.log(`Current period usage: ${balance.usage_summary.current_period_usage}`);
```

## List Voices

### Get All Voices

```javascript
const { voices, pagination } = await neospeech.voices.list();

console.log(`Found ${pagination.total} voices`);

voices.forEach(voice => {
  console.log(`${voice.name} (${voice.id}): ${voice.language}`);
});
```

### Filter Voices

```javascript
// Get female US English voices
const femaleVoices = await neospeech.voices.list({
  gender: 'female',
  locale: 'en-US'
});

// Search for professional voices
const professionalVoices = await neospeech.voices.list({
  search: 'professional'
});

// Paginated results
const page1 = await neospeech.voices.list({ limit: 10, offset: 0 });
const page2 = await neospeech.voices.list({ limit: 10, offset: 10 });
```

### Get All Voices with Pagination

```javascript
async function getAllVoices() {
  const allVoices = [];
  let offset = 0;
  const limit = 50;

  while (true) {
    const result = await neospeech.voices.list({ limit, offset });
    allVoices.push(...result.voices);

    console.log(`Retrieved ${allVoices.length} of ${result.pagination.total}`);

    if (allVoices.length >= result.pagination.total) {
      break;
    }

    offset += limit;
  }

  return allVoices;
}
```

## List Models

```javascript
const { models } = await neospeech.models.list();

models.forEach(model => {
  console.log(`${model.name}: ${model.quality} quality, ${model.avg_latency_ms}ms latency`);
});
```

## Error Handling

### Basic Error Handling

```javascript
const { NeoSpeechError } = require('neospeech-io');

try {
  const audio = await neospeech.audio.speech({
    input: 'test',
    voice: 'lyra',
    model: 'aurora-4'
  });
} catch (error) {
  if (error instanceof NeoSpeechError) {
    console.error(`Error [${error.code}]: ${error.message}`);
    console.log(`Status: ${error.status}`);
    console.log(`Retryable: ${error.retryable}`);

    if (error.isRateLimitError()) {
      console.log('Rate limited. Please wait and retry.');
    } else if (error.isAuthError()) {
      console.log('Check your API key.');
    }
  }
}
```

### Retry with Exponential Backoff

```javascript
async function generateSpeechWithRetry(text, voice, model, maxRetries = 3) {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await neospeech.audio.speech({
        input: text,
        voice: voice,
        model: model
      });
    } catch (error) {
      const isLastAttempt = attempt === maxRetries - 1;

      if (!error.retryable || isLastAttempt) {
        throw error;
      }

      const delay = Math.pow(2, attempt) * 1000;
      console.log(`Attempt ${attempt + 1} failed. Retrying in ${delay}ms...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

## Rate Limiting

### Request Queue

```javascript
class RequestQueue {
  constructor(maxConcurrent = 18) {
    this.maxConcurrent = maxConcurrent;
    this.queue = [];
    this.active = 0;
  }

  async add(requestFn) {
    return new Promise((resolve, reject) => {
      this.queue.push({ requestFn, resolve, reject });
      this.processQueue();
    });
  }

  async processQueue() {
    if (this.active >= this.maxConcurrent || this.queue.length === 0) {
      return;
    }

    const item = this.queue.shift();
    this.active++;

    try {
      const result = await item.requestFn();
      item.resolve(result);
    } catch (error) {
      item.reject(error);
    } finally {
      this.active--;
      this.processQueue();
    }
  }
}

// Usage
const queue = new RequestQueue(18);

async function queuedGenerateSpeech(text, voice, model) {
  return queue.add(() =>
    neospeech.audio.speech({ input: text, voice, model })
  );
}

// Process multiple requests safely
const texts = ['text1', 'text2', 'text3'];
const audios = await Promise.all(
  texts.map(text => queuedGenerateSpeech(text, 'lyra', 'aurora-3.5'))
);
```

## Batch Processing

```javascript
async function batchGenerateSpeech(texts, voice, model) {
  const results = await Promise.all(
    texts.map(text =>
      neospeech.audio.speech({ input: text, voice, model })
    )
  );

  return results;
}

const texts = ['First message', 'Second message', 'Third message'];
const audios = await batchGenerateSpeech(texts, 'kai', 'turbo-3');

// Save each audio file
audios.forEach((audio, index) => {
  fs.writeFileSync(`output-${index + 1}.mp3`, Buffer.from(audio));
});
```

## TypeScript Support

Full TypeScript support included:

```typescript
import NeoSpeech, { SpeechOptions, NeoSpeechError } from 'neospeech-io';

const neospeech = new NeoSpeech(process.env.NEOSPEECH_API_KEY!);

const options: SpeechOptions = {
  input: 'Hello, TypeScript!',
  voice: 'lyra',
  model: 'aurora-4'
};

const audio: ArrayBuffer = await neospeech.audio.speech(options);
```

## Using Without SDK (Raw Fetch)

If you prefer not to use the SDK:

```javascript
async function generateSpeechRaw(text, voice, model) {
  const response = await fetch('https://api.neospeech.io/v1/audio/speech', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.NEOSPEECH_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      input: text,
      voice: voice,
      model: model
    })
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.message || `HTTP ${response.status}`);
  }

  return await response.arrayBuffer();
}
```

## Related Resources

<CardGroup cols={2}>
  <Card title="Python Examples" icon="python" href="/examples/python">
    Python SDK examples
  </Card>
  <Card title="cURL Examples" icon="terminal" href="/examples/curl">
    Command-line examples
  </Card>
  <Card title="API Reference" icon="book" href="/api/text-to-speech">
    Complete API documentation
  </Card>
  <Card title="Best Practices" icon="lightbulb" href="/guides/best-practices">
    Optimization tips
  </Card>
</CardGroup>
