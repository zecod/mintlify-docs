---
title: "POST /v1/audio/stream"
description: Convert text to speech with real-time streaming audio delivery
api: "POST https://api.neospeech.io/v1/audio/stream"
---

## Overview

Generate high-quality speech audio from text with real-time streaming. Audio chunks are delivered progressively using chunked transfer encoding, enabling playback before generation completes.

<Info>For complete audio files, use the [speech endpoint](/api-reference/speech) instead</Info>

## Authentication

<ParamField header="Authorization" type="string" required>
  Bearer token with your API key: `Bearer sk-your-api-key-here`
</ParamField>

## Request Body

<ParamField body="input" type="string" required>
  Text to convert to speech

  **Constraints:**
  - Maximum 5,000 characters
  - Must be a non-empty string
</ParamField>

<ParamField body="voice" type="string" required>
  Voice identifier

  **Popular voices:** `lyra`, `kai`, `zara`, `vega`

  [View all 45+ voices](/api-reference/voices)
</ParamField>

<ParamField body="model" type="string" required>
  Audio model for generation

  **Options:**
  - `aurora-4` - Premium quality (48kHz, 192kbps)
  - `aurora-3.5` - High quality (48kHz, 96kbps)
  - `aurora-3` - Standard quality (24kHz, 160kbps)
  - `turbo-3` - Fast processing (16kHz, 64kbps)
  - `mini-2` - Lightweight (24kHz, 48kbps)

  [Learn more about models](/concepts/models)
</ParamField>

<ParamField body="pitch" type="string" default="+0%">
  Voice pitch adjustment

  **Range:** `-50%` to `+50%`

  **Examples:** `"+10%"`, `"-5%"`, `"+0%"`
</ParamField>

<ParamField body="style" type="string" default="calm">
  Speech style emotion

  **Options:** `calm`, `excited`, `cheerful`, `sad`
</ParamField>

<ParamField body="styleDegree" type="string" default="1.5">
  Style intensity level

  **Range:** `0.5` to `2.0`

  Higher values increase style expressiveness
</ParamField>

<ParamField body="contour" type="string" default="(0%,+20Hz) (10%,-2st) (40%,+10Hz)">
  Advanced pitch contour pattern

  Define custom pitch variations throughout speech
</ParamField>

<ParamField body="lang" type="string" default="en-US">
  Language code for pronunciation

  **Examples:** `en-US`, `en-GB`, `fr-FR`, `de-DE`
</ParamField>

## Response

### Success Response

**Status Code:** `200 OK`

**Content-Type:** `audio/mpeg`

**Transfer-Encoding:** `chunked`

**Body:** Streaming binary MP3 audio chunks

**Headers:**
```
Content-Type: audio/mpeg
Transfer-Encoding: chunked
X-Character-Count: 47
X-Model-Used: aurora-4
X-Voice-Used: Lyra
```

<ResponseField name="X-Character-Count" type="integer">
  Number of characters processed
</ResponseField>

<ResponseField name="X-Model-Used" type="string">
  Model used for generation
</ResponseField>

<ResponseField name="X-Voice-Used" type="string">
  Voice name used
</ResponseField>

### Error Responses

<AccordionGroup>
  <Accordion title="400 Bad Request">
    Invalid request parameters

    ```json
    {
      "success": false,
      "message": "Invalid 'voice' parameter. A valid voice identifier is required."
    }
    ```
  </Accordion>

  <Accordion title="401 Unauthorized">
    Missing or invalid API key

    ```json
    {
      "success": false,
      "message": "Authorization header is missing or invalid."
    }
    ```
  </Accordion>

  <Accordion title="403 Forbidden">
    Access denied (Free plan or disabled key)

    ```json
    {
      "success": false,
      "message": "Access denied. This API is only available for Pro and Business plans."
    }
    ```
  </Accordion>

  <Accordion title="404 Not Found">
    Voice not found

    ```json
    {
      "success": false,
      "message": "The requested voice does not exist."
    }
    ```
  </Accordion>

  <Accordion title="413 Payload Too Large">
    Text exceeds 5,000 character limit

    ```json
    {
      "success": false,
      "message": "The provided text exceeds the 5000-character limit."
    }
    ```
  </Accordion>

  <Accordion title="500 Internal Server Error">
    Server processing error

    ```json
    {
      "success": false,
      "message": "Processing failed",
      "retryable": false
    }
    ```
  </Accordion>
</AccordionGroup>

## Examples

<CodeGroup>

```bash cURL
curl -X POST "https://api.neospeech.io/v1/audio/stream" \
  -H "Authorization: Bearer sk-your-api-key-here" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "This is a streaming test for real-time audio delivery.",
    "voice": "lyra",
    "model": "aurora-4",
    "pitch": "+0%",
    "style": "calm"
  }' \
  --output stream.mp3 \
  --no-buffer
```

```javascript JavaScript
const apiKey = process.env.NEOSPEECH_API_KEY;

async function streamSpeech(text) {
  const response = await fetch('https://api.neospeech.io/v1/audio/stream', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      input: text,
      voice: 'lyra',
      model: 'aurora-4',
      style: 'calm'
    })
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.message);
  }

  // Get metadata
  const charCount = response.headers.get('X-Character-Count');
  const modelUsed = response.headers.get('X-Model-Used');
  const voiceUsed = response.headers.get('X-Voice-Used');

  console.log(`Streaming ${charCount} characters with ${voiceUsed} voice`);

  // Process stream
  const reader = response.body.getReader();
  const chunks = [];

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    chunks.push(value);
    console.log(`Received chunk: ${value.length} bytes`);
  }

  // Combine chunks into complete audio
  const audioBlob = new Blob(chunks, { type: 'audio/mpeg' });
  return audioBlob;
}
```

```python Python
import requests
import os

def stream_speech(text):
    response = requests.post(
        'https://api.neospeech.io/v1/audio/stream',
        headers={
            'Authorization': f'Bearer {os.getenv("NEOSPEECH_API_KEY")}',
            'Content-Type': 'application/json'
        },
        json={
            'input': text,
            'voice': 'lyra',
            'model': 'aurora-4',
            'style': 'calm'
        },
        stream=True
    )

    if response.status_code == 200:
        # Get metadata
        char_count = response.headers.get('X-Character-Count')
        model_used = response.headers.get('X-Model-Used')
        voice_used = response.headers.get('X-Voice-Used')

        print(f'Streaming {char_count} characters with {voice_used} voice')

        # Process stream chunks
        chunks = []
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                chunks.append(chunk)
                print(f'Received chunk: {len(chunk)} bytes')

        return b''.join(chunks)
    else:
        error = response.json()
        raise Exception(error.get('message', 'Request failed'))
```

</CodeGroup>

## Streaming Benefits

<CardGroup cols={2}>
  <Card title="Low Latency" icon="gauge-high">
    Start playback immediately as first chunks arrive
  </Card>
  <Card title="Memory Efficient" icon="memory">
    Process audio chunks without loading entire file
  </Card>
  <Card title="Better UX" icon="face-smile">
    Users hear audio faster with progressive delivery
  </Card>
  <Card title="Real-Time Apps" icon="bolt">
    Perfect for conversational AI and live applications
  </Card>
</CardGroup>

## Rate Limits

| Plan | Concurrent Requests | Timeout |
|------|---------------------|---------|
| Pro | 18 | 120s |
| Business | 25 | 120s |

<Warning>
Streaming requests count toward your concurrent request limits
</Warning>

## Best Practices

### Handle Stream Errors

Implement proper error handling for stream interruptions:

```javascript
async function safeStreamSpeech(text) {
  try {
    const response = await fetch('https://api.neospeech.io/v1/audio/stream', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ input: text, voice: 'lyra', model: 'aurora-4' })
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.message);
    }

    const reader = response.body.getReader();
    const chunks = [];

    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        chunks.push(value);
      }
    } catch (streamError) {
      console.error('Stream interrupted:', streamError);
      throw streamError;
    }

    return new Blob(chunks, { type: 'audio/mpeg' });
  } catch (error) {
    console.error('Streaming failed:', error.message);
    throw error;
  }
}
```

### Save Streamed Audio

<CodeGroup>

```javascript Node.js
import fs from 'fs';

const audioBlob = await streamSpeech('Hello world');
const buffer = Buffer.from(await audioBlob.arrayBuffer());
fs.writeFileSync('stream.mp3', buffer);
```

```python Python
audio_content = stream_speech('Hello world')
with open('stream.mp3', 'wb') as f:
    f.write(audio_content)
```

</CodeGroup>

### Play Audio in Browser

```javascript
async function playStreamedAudio(text) {
  const audioBlob = await streamSpeech(text);
  const audioUrl = URL.createObjectURL(audioBlob);

  const audio = new Audio(audioUrl);
  audio.play();

  audio.onended = () => {
    URL.revokeObjectURL(audioUrl);
  };
}
```

## Related Endpoints

<CardGroup cols={2}>
  <Card title="Standard TTS" icon="file-audio" href="/api-reference/speech">
    Complete audio file generation
  </Card>
  <Card title="List Voices" icon="microphone" href="/api-reference/voices">
    Get available voices
  </Card>
  <Card title="Streaming Guide" icon="book" href="/guides/streaming">
    Learn streaming best practices
  </Card>
  <Card title="Check Balance" icon="wallet" href="/api-reference/balance">
    View usage and credits
  </Card>
</CardGroup>