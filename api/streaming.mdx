---
title: Streaming Audio
description: Stream audio in real-time as it's generated
api: "POST https://api.neospeech.io/v1/audio/stream"
---

Get audio chunks progressively instead of waiting for the complete file. Perfect for real-time applications like chatbots and voice assistants.

## Request

Streaming uses the same payload as regular speech generation, but audio arrives incrementally:

```bash
curl -X POST "https://api.neospeech.io/v1/audio/stream" \
  -H "Authorization: Bearer sk-your-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, welcome to NeoSpeech",
    "voice": "lyra",
    "model": "turbo-3"
  }' \
  --output stream.mp3 \
  --no-buffer
```

## Parameters

<ParamField header="Authorization" type="string" required>
  Bearer token: `Bearer sk-your-api-key`
</ParamField>

<ParamField body="input" type="string" required>
  Text to convert (up to 5,000 characters). Audio streams as it's generated.
</ParamField>

<ParamField body="voice" type="string" required>
  Voice identifier like `lyra`, `kai`, or `zara`. [See all voices](/api/voices)
</ParamField>

<ParamField body="model" type="string" required>
  Recommended: `turbo-3` for lowest latency or `mini-2` for lightweight streaming. Other models are supported but send larger chunks.
</ParamField>

## Response

Returns chunked MP3 data with `Transfer-Encoding: chunked` header. Audio starts playing before generation completes.

## Common patterns

### Stream and save

<CodeGroup>

```javascript Node.js
const response = await fetch('https://api.neospeech.io/v1/audio/stream', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${apiKey}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    input: 'Your text here',
    voice: 'lyra',
    model: 'turbo-3'
  })
});

const reader = response.body.getReader();
const chunks = [];

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  chunks.push(value);
  console.log(`Received ${value.length} bytes`);
}

const audioBlob = new Blob(chunks, { type: 'audio/mpeg' });
```

```python Python
response = requests.post(
    'https://api.neospeech.io/v1/audio/stream',
    headers={'Authorization': f'Bearer {apiKey}'},
    json={'input': 'Your text here', 'voice': 'lyra', 'model': 'turbo-3'},
    stream=True
)

chunks = []
for chunk in response.iter_content(chunk_size=8192):
    if chunk:
        chunks.append(chunk)
        print(f'Received {len(chunk)} bytes')

audio_data = b''.join(chunks)
```

</CodeGroup>

### Play in browser

```javascript
async function playStreaming(text) {
  const response = await fetch('https://api.neospeech.io/v1/audio/stream', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      input: text,
      voice: 'lyra',
      model: 'turbo-3'
    })
  });

  const reader = response.body.getReader();
  const chunks = [];

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    chunks.push(value);
  }

  const audioBlob = new Blob(chunks, { type: 'audio/mpeg' });
  const audioUrl = URL.createObjectURL(audioBlob);

  const audio = new Audio(audioUrl);
  audio.play();
}
```

### Handle interruptions

```javascript
let controller = new AbortController();

async function streamWithAbort(text) {
  try {
    const response = await fetch('https://api.neospeech.io/v1/audio/stream', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ input: text, voice: 'lyra', model: 'turbo-3' }),
      signal: controller.signal
    });

    const reader = response.body.getReader();
    const chunks = [];

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      chunks.push(value);
    }

    return new Blob(chunks, { type: 'audio/mpeg' });
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Stream cancelled');
    }
    throw error;
  }
}

// Cancel the stream
controller.abort();
```

## Why streaming?

Streaming delivers audio faster because you don't wait for complete generation. Users hear the first words within a second, making your app feel more responsive.

Use streaming when:
- Building conversational AI or chatbots
- Creating real-time voice experiences
- User experience matters more than file size
- You need low perceived latency

Use regular TTS when:
- Generating audio files for storage
- Creating podcasts or audiobooks
- File size optimization matters
- You process audio in batches
